{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06431809",
   "metadata": {},
   "source": [
    "# Project: Data Pipeline with Pandas and MongoDB\n",
    "\n",
    "## Architecture of the solution\n",
    "\n",
    "This project utilizes a data pipeline where:\n",
    "- **Pandas** is used to read and transform the data from a CSV file.\n",
    "- **MongoDB** acts as the document database to store the transformed data.\n",
    "- The pipeline is linear: CSV → Pandas → MongoDB.\n",
    "\n",
    "**Note:** Spark is not used in this implementation. If required, this pipeline could be extended with PySpark for distributed processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f47e3b",
   "metadata": {},
   "source": [
    "## Schema Design and Indexing Strategy\n",
    "\n",
    "The data is structured in the following document format in MongoDB:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"date\": ISODate(\"2020-03-15T00:00:00Z\"),\n",
    "    \"country\": \"Finland\",\n",
    "    \"stats\": {\n",
    "        \"cumulative_total_cases\": 100,\n",
    "        \"daily_new_cases\": 10,\n",
    "        \"active_cases\": 80,\n",
    "        \"cumulative_total_deaths\": 5,\n",
    "        \"daily_new_deaths\": 1\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "This format is chosen for clarity and efficiency when querying COVID-19 statistics per country and date.\n",
    "\n",
    "### Indexes\n",
    "\n",
    "Indexes are created on:\n",
    "- `date`\n",
    "- `country`\n",
    "- Composite index on `date` and `country`\n",
    "\n",
    "These indexes help in:\n",
    "- Fast retrieval of data for a given country\n",
    "- Efficient filtering for reports on specific dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88578c",
   "metadata": {},
   "source": [
    "## Step-by-step Implementation\n",
    "\n",
    "This section details the data loading, cleaning, transformation, and insertion into MongoDB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c87447bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import time\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client['Project']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571c8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"Covid19.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Project\"]\n",
    "collection = db[\"CovidData\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d857d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 184787 entries, 0 to 184786\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   date                     184787 non-null  datetime64[ns]\n",
      " 1   country                  184787 non-null  object        \n",
      " 2   cumulative_total_cases   184787 non-null  float64       \n",
      " 3   daily_new_cases          174329 non-null  float64       \n",
      " 4   active_cases             166747 non-null  float64       \n",
      " 5   cumulative_total_deaths  178227 non-null  float64       \n",
      " 6   daily_new_deaths         157850 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 9.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert and clean date and numeric columns\n",
    "print(df.info())\n",
    "\n",
    "# Fix column names (strip spaces just in case)\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "# Convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Make sure numerical columns are numbers\n",
    "numerical_columns = [\n",
    "    'cumulative_total_cases', 'daily_new_cases',\n",
    "    'active_cases', 'cumulative_total_deaths', 'daily_new_deaths'\n",
    "]\n",
    "\n",
    "for col in numerical_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Drop rows with missing critical data\n",
    "df.dropna(subset=['date', 'country'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d1b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Structure stats as a subdocument\n",
    "df['stats'] = df.apply(lambda row: {\n",
    "    \"cumulative_total_cases\": row[\"cumulative_total_cases\"],\n",
    "    \"daily_new_cases\": row[\"daily_new_cases\"],\n",
    "    \"active_cases\": row[\"active_cases\"],\n",
    "    \"cumulative_total_deaths\": row[\"cumulative_total_deaths\"],\n",
    "    \"daily_new_deaths\": row[\"daily_new_deaths\"]\n",
    "}, axis=1)\n",
    "\n",
    "# Keep only essential columns for insertion\n",
    "mongo_df = df[['date', 'country', 'stats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9034c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date_1_country_1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Insert data into MongoDB\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Project\"]\n",
    "collection = db[\"CovidData\"]\n",
    "\n",
    "# Convert to records\n",
    "data_to_insert = mongo_df.to_dict(\"records\")\n",
    "\n",
    "# Insert the data\n",
    "collection.insert_many(data_to_insert)\n",
    "\n",
    "# Create indexes for query performance\n",
    "collection.create_index([(\"date\", 1)])\n",
    "collection.create_index([(\"country\", 1)])\n",
    "collection.create_index([(\"date\", 1), (\"country\", 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60129ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Example queries\n",
    "# All data for Finland\n",
    "collection.find({\"country\": \"Finland\"})\n",
    "\n",
    "# Data for Finland on a specific date\n",
    "from datetime import datetime\n",
    "collection.find({\"country\": \"Finland\", \"date\": datetime(2020, 3, 15)})\n",
    "\n",
    "for doc in collection.find({\"daily_new_cases\": {\"$gt\": 100}}):\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad2758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c84aa80b",
   "metadata": {},
   "source": [
    "## MongoDB Query Performance Tuning\n",
    "\n",
    "We use `create_index()` on key fields such as `date` and `country`. These significantly reduce query time for analytics.\n",
    "\n",
    "You can use the following command to analyze query plans:\n",
    "```python\n",
    "collection.find({\"country\": \"Finland\"}).explain()\n",
    "```\n",
    "This gives insight into how MongoDB uses indexes and can help you identify further optimization opportunities.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
